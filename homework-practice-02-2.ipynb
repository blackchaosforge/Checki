{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 2\n",
    "\n",
    "### Общая информация\n",
    "Дата выдачи: 3 ноября 2017\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 19 ноября (за каждый день просрочки снимается 1 балл)\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 26 ноября."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### О задании\n",
    "\n",
    "В этом задании вы:\n",
    "- обучите линейную регрессию, познакомитесь с метриками качества в задачах регресии\n",
    "- реализуете логистическую регрессию и её обучение градиентным спуском\n",
    "- настроите метод опорных векторов, визуализируете опорные вектора\n",
    "- познакомитесь с калибровочными кривыми и сравните вероятности, выдаваемые логистической регрессией и методом опорных векторов\n",
    "- изучите методы работы с категориальными переменными\n",
    "- в качестве бонуса попробуете библиотеку vowpal wabbit.\n",
    "\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "\n",
    "### Формат сдачи\n",
    "Для сдачи задания переименуйте получившийся файл *.ipynb в соответствии со следующим форматом: homework-practice-02-Username.ipynb, где Username — ваша фамилия и имя на латинице именно в таком порядке (например, homework-practice-02-IvanovIvan.ipynb). Приложите модули с кодом logreg.py и заархивируйте оба файла вместе в zip формат. Имя архива должно быть homework-practice-02-Username.zip)\n",
    "\n",
    "Далее отправьте этот файл на hse.cs.ml+<номер группы>@gmail.com (например, hse.cs.ml+151@gmail.com для студентов группы БПМИ-151).\n",
    "\n",
    "\n",
    "Для удобства проверки самостоятельно посчитайте свою максимальную оценку (исходя из набора решенных задач) и укажите ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Оценка:** 10.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части мы кратко познакомимся с линейной регрессией.\n",
    "\n",
    "Для начала загрузим данные и разделим их на обучающую и тестовую выборки в соотношении 7 к 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, train_size=0.7, random_state=241)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучение линейной регрессии.\n",
    "\n",
    "**(1 балл)**\n",
    "\n",
    "Обучите линейную регрессию с $L_1$ (Lasso) и $L_2$ (Ridge) регуляризаторами (используйте параметры по умолчанию). Посмотрите, какое количество коэффициентов близко к 0 (степень близости к 0 определите сами из разумных пределов). Постройте график зависимости числа ненулевых коэффициентов от коэффицента регуляризации (перебирайте значения по логарифмической сетке от $10^{-3}$ до $10^3$). Согласуются ли результаты с вашими ожиданиями?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge"
    "nz = lambda x: (np.abs(x) < (np.abs(x).max() * 0.1 / 100)) | (np.abs(x) < 0.01)\n",
    "nnz = lambda x: len(x) - nz(x).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_посмотрим со стандартными коэффициентами_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.        ,    224.32666397        ,  0.        ,   43.11196734,\n",
       "          0.        ,    66.13568398        ,   -0.        ,    0.        ,\n",
       "        0.        ,    0.        ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ True,  False, True, False,  True,  False,  True,  True, True,  True], dtype=bool)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lasso_alpha_coef(alpha = 1.0):\n",
    "    lasso = Lasso(alpha = alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    return lasso.coef_\n",
    "\n",
    "coef = lasso_alpha_coef()\n",
    "display(coef)\n",
    "display(nz(coef))\n",
    "nz(coef).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  25.50214770,  -56.44103894,  345.51233779,  387.34060060 ,\n",
       "         87.7582564 ,   -12.71841782, -260.68825228,  133.93166075,\n",
       "        252.35668992,  3.82974571 ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False, False], dtype=bool)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ridge_alpha_coef(alpha = 1.0):\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    return ridge.coef_\n",
    "    \n",
    "coef = ridge_alpha_coef()\n",
    "display(coef)\n",
    "display(nz(coef))\n",
    "nz(coef).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e-03,   1.42510267e-03,   2.03091762e-03,\n",
       "         2.89426612e-03,   4.12462638e-03,   5.87801607e-03,\n",
       "         8.37677640e-03,   1.19377664e-02,   1.70125428e-02,\n",
       "         2.42446202e-02,   3.45510729e-02,   4.92388263e-02,\n",
       "         7.01703829e-02,   1.00000000e-01,   1.42510267e-01,\n",
       "         2.03091762e-01,   2.89426612e-01,   4.12462638e-01,\n",
       "         5.87801607e-01,   8.37677640e-01,   1.19377664e+00,\n",
       "         1.70125428e+00,   2.42446202e+00,   3.45510729e+00,\n",
       "         4.92388263e+00,   7.01703829e+00,   1.00000000e+01,\n",
       "         1.42510267e+01,   2.03091762e+01,   2.89426612e+01,\n",
       "         4.12462638e+01,   5.87801607e+01,   8.37677640e+01,\n",
       "         1.19377664e+02,   1.70125428e+02,   2.42446202e+02,\n",
       "         3.45510729e+02,   4.92388263e+02,   7.01703829e+02,\n",
       "         1.00000000e+03])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_list = 10**(np.linspace(start = -3, stop = 3, num = 40))\n",
    "alpha_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Lasso - Ступенчатый спуск от от $10^{-3}$ до $10^0$ , затем коэффициенты сходят на нет. Ridge - коэффициенты остаются незатронутыми.  - L1 проводит отбор признаков с увеличением alpha, а L2 - уменьшает все одновременно_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте для Ridge-регрессии следующие метрики: $RMSE$, $MAE$, $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test sample. RMSE: 3397.8297483174571. MAE: 49.60238039575233. R2: 0.3540585757368463.'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ridge_alpha_coef(alpha = 1.0):\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_pred = ridge.predict(X_test)\n",
    "    rmse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "rmse, mae, r2 = ridge_alpha_coef()\n",
    "f\"Test sample. RMSE: {rmse}. MAE: {mae}. R2: {r2}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите на обучающей выборке для Ridge-регрессии коэффициент регуляризации (перебирайте значения по логарифмической сетке от $10^{-3}$ до $10^3$) для каждой из метрик. Для этого воспользуйтесь GridSearchCV и KFold из sklearn. Постройте графики зависимости фукнции потерь от коэффициента регуляризации. <br><br> Посчитайте те же метрики снова. Заметно ли изменилось качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "name": "stdout",
   "output_type": "stream",
   "text": [
    "Зависимость метрики r2 - максимум при alpha [0.0020309176209047349]. Номер alpha - 2
    Зависимость метрики neg_mean_squared_error - максимум при alpha [0.0020309176209047349]. Номер alpha - 2
    Зависимость метрики neg_mean_absolute_error - максимум при alpha [0.0014251026703029977]. Номер alpha - 1\n"
   ]
  }
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{'alpha': alpha_list}]\n",
    "cv_kfold = KFold(len(X_train), n_folds = 5, random_state = 1)\n",
    "for metric in ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']:\n",
    "    ridge_grid = GridSearchCV(Ridge(), param_grid=tuned_parameters, cv = cv_kfold, scoring=metric)\n",
    "    ridge_grid.fit(X_train, y_train)\n",
    "    ridge_grid.cv_results_\n",
    "    scores = ridge_grid.cv_results_['mean_test_score']\n",
    "    plt.title(f'Зависимость метрики {metric} от коэффициента регурялизации для Ridge регрессии. CV = 5')\n",
    "    plt.semilogx(ridge_grid.cv_results_['param_alpha'].data, scores)\n",
    "    plt.show()\n",
    "    max_n = np.where(scores == scores.max())[0]\n",
    "    print(f\"Максимум метрики наблюдался при alpha {ridge_grid.cv_results_['param_alpha'].data[max_n]}. \" + \\\n",
    "          f\"Номер alpha - {max_n[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Для тестовой выборки_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test sample. RMSE: 3116.028759552656. MAE: 47.12406424926582. R2: 0.41325848986842895.'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse, mae, r2 = ridge_alpha_coef(0.002)\n",
    "f\"Test sample. RMSE: {rmse}. MAE: {mae}. R2: {r2}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Вывод - значение alpha 1.0 по умолчанию слишком регуляризовало регрессор, при снижении - метрика улучшилась_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__Задание 2.__ Поиск объектов-выбросов\n",
    "\n",
    "**(0.5 балла)**\n",
    "\n",
    "Как известно, MSE сильно штрафует за большие ошибки на объектах-выбросах. С помощью cross_val_predict сделайте Out-of-Fold предсказания для обучающей выборки. Посчитайте ошибки и посмотрите на их распределение (plt.hist). Что вы видите?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_pred = cross_val_predict(Ridge(alpha=0.002), X_train, y_train, cv = len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте удалить объекты-выбросы из обучающей выборки (что считать или не считать выбросами на ваше усмотрение). Обучите модель заново и посмотрите на качество на отложенной выборке (учитывайте, что там тоже могут быть выбросы, с которыми вы ничего не можете сделать). Стало ли лучше? Чем вы можете объяснить это?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Примем, что больше 10000 квадрата ошибки на обучающей - выбросы_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_junk = (cv_pred - y_train)**2 <= 10000\n",
    "X_no_junk = X_train[no_junk]\n",
    "y_no_junk = y_train[no_junk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test sample. RMSE: 3254.7220488280745. MAE: 47.20438008437341. R2: 0.3871428419479468.'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_no_junk = Ridge(alpha = 0.002)\n",
    "ridge_no_junk.fit(X_no_junk, y_no_junk)\n",
    "pred_no_junk = ridge_no_junk.predict(X_test)\n",
    "\n",
    "rmse = mean_squared_error(y_test, pred_no_junk)\n",
    "mae = mean_absolute_error(y_test, pred_no_junk)\n",
    "r2 = r2_score(y_test, pred_no_junk)\n",
    "f\"Test sample. RMSE: {rmse}. MAE: {mae}. R2: {r2}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Лучше не стало, похоже выбросы таковыми не являлось, а несли в себе полезную информацию._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части мы будем реализовывать один из самых простых бинарных классификаторов — логистическую регрессию и её обучение с помощью обычного (полного) и стохастического градиентных спусков.\n",
    "\n",
    "Если кратко, то обучение логистической регрессии с $L_2$-регуляризацией можно записать следующим образом:\n",
    "\n",
    "$$\n",
    "Q(w, X) = \\frac{1}{l} \\sum_{i=1}^{l} \\log (1 + \\exp(- y_i \\langle w, x_i \\rangle )) + \\frac{\\lambda_2}{2} \\lVert w \\rVert _2^2 \\to \\min_w\n",
    "$$\n",
    "\n",
    "Считаем, что $y_i \\in \\{-1, +1\\}$, а нулевым признаком сделан единичный (то есть $w_0$ соответствует свободному члену). Искать $w$ будем с помощью градиентного спуска:\n",
    "\n",
    "$$\n",
    "w^{(k+1)} = w^{(k)} - \\alpha \\nabla_w Q(w, X)\n",
    "$$\n",
    "\n",
    "В случае полного градиентного спуска $\\nabla_w Q(w, X)$ считается напрямую (как есть, то есть, используя все объекты выборки). В случае стохастического градиентного спуска $\\nabla_w Q(w, X) \\approx \\nabla_w q_{i_k} (w)$, где $i_k$ — случайно выбранный номер слагаемого из функционала (регуляризатор можно внести в сумму, предварительно умножив и разделив на $l$). Длину шага $\\alpha > 0$ в рамках данного задания предлагается брать равной некоторой малой константе.\n",
    "\n",
    "Формулу для градиента функции потерь логистической регрессии вы должны были выводить в рамках одной из задач четвёртого теоретического домашнего задания. Но на всякий случай мы её повторим. Градиент по объекту $x_i$ считается по следующей формуле:\n",
    "\n",
    "$$\n",
    "\\nabla_w Q(w, x_i) = - \\frac{y_i x_i}{1 + \\exp(y_i \\langle w, x_i \\rangle)} + \\lambda_2 w\n",
    "$$\n",
    "\n",
    "На самом деле неправильно регуляризировать свободный член $w_0$ (то есть при добавлении градиента для $w_0$ не надо учитывать слагаемое с $\\lambda_2$). Но в рамках этого задания мы не обращаем на это внимания и работаем со всеми вектором весов одинаково. \n",
    "\n",
    "В качестве критерия останова необходимо использовать (одновременно):\n",
    "- проверку на евклидовую норму разности весов на двух соседних итерациях (например, меньше некоторого малого числа порядка $10^{-6}$) — параметр tolerance\n",
    "- достижение максимального числа итераций (например, 10000) — параметр max\\_iter.\n",
    "\n",
    "Инициализировать веса можно случайным образом или нулевым вектором.\n",
    "\n",
    "Вероятность принадлежности объекта $x$ классу $+1$ вычисляется следующим образом:\n",
    "\n",
    "$$\n",
    "P(y = +1 | x) = \\frac{1}{1 + \\exp(- \\langle w, x \\rangle )}\n",
    "$$\n",
    "\n",
    "Не забывайте, что матрицу объекты-признаки $X$ необходимо предварительно нормировать (то есть привести каждый признак к одному и тому же масштабу одним из 2 способов, разобранных на лекциях). Для этого можно воспользоваться StandardScaler или сделать это вручную.\n",
    "\n",
    "В логистической регрессии также можно использовать $L_1$-регуляризацию. Тогда в функцию потерь добавится слагаемое $\\lambda_1 \\lVert w \\rVert _1$. В формуле для вычисления градиента фукнции потерь по вектору коэффициентов это слагаемое будет соответствовать $\\lambda_1 sgn(w)$, где $sgn$ — вычисление знака числа, применяемое к вектору коэффициентов поэлементо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Реализация обучения и применения логистической регресии c $L_2$-регуляризацией. \n",
    "\n",
    "**(2.5 балла)**\n",
    "\n",
    "Используйте для этого указанные ниже прототипы. Для эффективности все вычисления производите в векторизованной форме без циклов (кроме самих итераций градиентного спуска). Сгенерируйте с помощью функции make\\_classification из модуля sklearn.datasets небольшую выборку для тестирования и исследования (выборка не должна быть слишком простой для классификации; также не забудьте проверить, что метки объектов из необходимого нам множества). Постройте следующие графики (для полного и стохастического градиентного спуска на одном графике):\n",
    "- функции потерь от номера итерации обучения\n",
    "- затраченного времени от номера итерации обучения\n",
    "\n",
    "Возьмите параметр регуляризации $\\lambda_2=1$, точность $tolerance=10^{-6}$, максимальное число итераций $max\\_iter=1000$. Подберите оптимальную на ваш взгляд величину шага градиентного спуска. \n",
    "\n",
    "Сделайте выводы о том, чем различается на практике обучение с помощью стохастического градиентного спуска по сравнению с полным градиентным спуском.\n",
    "\n",
    "В этом задании не обращайте внимания на $\\lambda_1$, соответствующий $L_1$-регуляризации.\n",
    "\n",
    "Для численной устойчивости вам могут быть полезны функции: scipy.special.expit и numpy.logaddexp.\n",
    "\n",
    "__Важно:__ код с реализацией логистической регрессии необходимо также отправить на проверку в Яндекс.контест (ссылка [раз](https://official.contest.yandex.ru/contest/5704/problems/) и [альтернативная](https://contest.yandex.ru/contest/5704/problems/)). Не забывайте про pep8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My full 0.72230624\n",
      "My stochastic 0.7249152\n",
      "Sklearn 0.75541448\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "\n",
    "# noinspection PyPep8Naming\n",
    "class LogReg(BaseEstimator):\n",
    "    def __init__(self, lambda_1=0.0, lambda_2=1.0, gd_type='stochastic',\n",
    "                 tolerance=1e-4, max_iter=1000, w0=None, alpha=1e-3):\n",
    "        \"\"\"\n",
    "        lambda_1: L1 regularization param\n",
    "        lambda_2: L2 regularization param\n",
    "        gd_type: 'full' or 'stochastic'\n",
    "        tolerance: for stopping gradient descent\n",
    "        max_iter: maximum number of steps in gradient descent\n",
    "        w0: np.array of shape (d) - init weights\n",
    "        alpha: learning rate\n",
    "        \"\"\"\n",
    "        self.lambda_1 = lambda_1\n",
    "        self.lambda_2 = lambda_2\n",
    "        self.gd_type = gd_type\n",
    "        self.tolerance = tolerance\n",
    "        self.max_iter = max_iter\n",
    "        self.w0 = w0\n",
    "        self.alpha = alpha\n",
    "        self.w = None\n",
    "        self.loss_history = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d)\n",
    "        y: np.array of shape (l)\n",
    "        ---\n",
    "        output: self\n",
    "        \"\"\"\n",
    "        self.loss_history = []\n",
    "        self.time_history = []\n",
    "        self.w = np.random.uniform(0, 1e-6, size=(X.shape[1]))\n",
    "        if self.w0 is not None:\n",
    "            self.w = self.w0\n",
    "        start_time = time.time()\n",
    "        for i in range(self.max_iter):\n",
    "            current_loss = self.calc_loss(X, y)\n",
    "            w_old = self.w.copy()\n",
    "            if self.gd_type == 'full':\n",
    "                Xg, yg = X, y\n",
    "            else:\n",
    "                mask_size = X.shape[0] // 100\n",
    "                if mask_size < 1:\n",
    "                    mask_size = 1\n",
    "                mask = np.random.choice(X.shape[0], size=mask_size, replace=False)\n",
    "                mask = sorted(mask)\n",
    "                Xg, yg = X[mask, :], y[mask]\n",
    "            dQ = self.calc_gradient(Xg, yg) + self.lambda_2 * self.w\n",
    "            self.w -= self.alpha * dQ\n",
    "            self.loss_history.append(current_loss)\n",
    "            self.time_history.append(time.time() - start_time)\n",
    "            if abs(np.linalg.norm(self.w - w_old)) < self.tolerance:\n",
    "                break\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d)\n",
    "        ---\n",
    "        output: np.array of shape (l, 2) where\n",
    "        first column has probabilities of -1\n",
    "        second column has probabilities of +1\n",
    "        \"\"\"\n",
    "        if self.w is None:\n",
    "            raise Exception('Not trained yet')\n",
    "        probability = expit(np.dot(X, self.w))\n",
    "        formatted = [(1 - p, p) for p in probability]\n",
    "        return np.array(formatted)\n",
    "\n",
    "    def calc_gradient(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d) (l can be equal to 1 if stochastic)\n",
    "        y: np.array of shape (l)\n",
    "        ---\n",
    "        output: np.array of shape (d)\n",
    "        \"\"\"\n",
    "        return np.dot(X.T, -expit(-y * X.dot(self.w)) * y) / X.shape[0]\n",
    "\n",
    "    def calc_loss(self, X, y):\n",
    "        \"\"\"\n",
    "        X: np.array of shape (l, d)\n",
    "        y: np.array of shape (l)\n",
    "        ---\n",
    "        output: float\n",
    "        \"\"\"\n",
    "        s = np.mean(np.log(1 + np.exp(-y * (np.dot(X, self.w)))))\n",
    "        s2 = self.lambda_2 / 2 * np.dot(self.w, self.w)\n",
    "        return s + s2\n",
    "\n",
    "Xc, yc = make_classification(n_samples=10000, n_features=100, n_informative=25, n_redundant=5,\n",
    "                             random_state=1, class_sep=0.5, shift=0)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Xcc = Xc.copy()\n",
    "ycc = yc.copy()\n",
    "Xcc = np.hstack([np.ones((Xc.shape[0], 1)), Xc])\n",
    "scaler.fit(Xcc)\n",
    "Xcc = scaler.transform(Xcc)\n",
    "\n",
    "lr_full = LogReg(gd_type='full')\n",
    "lr_full.fit(Xcc, ycc)\n",
    "y_pred = lr_full.predict_proba(Xcc)[:, 1]\n",
    "print('My full', roc_auc_score(ycc, y_pred))\n",
    "\n",
    "lr_sto = LogReg(gd_type='stochastic')\n",
    "lr_sto.fit(Xcc, ycc)\n",
    "y_pred = lr_sto.predict_proba(Xcc)[:, 1]\n",
    "print('My stochastic', roc_auc_score(ycc, y_pred))\n",
    "\n",
    "\n",
    "lr_sklearn = LogisticRegression()\n",
    "lr_sklearn.fit(Xc, yc)\n",
    "y_pred = lr_sklearn.predict_proba(Xc)[:, 1]\n",
    "print('Sklearn', roc_auc_score(yc, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Стохастическая (1% от выборки на каждой итерации) сходится почти так же быстро как и полная, если смотреть по номеру итерации. Однако, не происходит быстрого провала в локальный оптимум и преждевременной остановки, как в случае полной_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_full = np.array(range(len(lr_full.loss_history))) + 1\n",
    "x_sto = np.array(range(len(lr_sto.loss_history))) + 1\n",
    "y_full = lr_full.loss_history\n",
    "y_sto = lr_sto.loss_history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Зависимость функции потерь от номера итерации')\n",
    "plt.xlabel('Номер итерации')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(x_full, y_full, 'b', x_sto, y_sto, 'r')\n",
    "plt.legend(['Full', 'Stochastic'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Если брать по времени, стохастическая сходится быстрее и лучше, чем полная_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_full = np.array(lr_full.time_history)\n",
    "x_sto = np.array(lr_sto.time_history)\n",
    "y_full = lr_full.loss_history\n",
    "y_sto = lr_sto.loss_history\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Зависимость функции потерь от времени')\n",
    "plt.xlabel('Время, с')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(x_full, y_full, 'b', x_sto, y_sto, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Бонусное задание.__ Реализация $L_1$-регуляризации и обучение с помощью субградиентного спуска.\n",
    "\n",
    "__(1.0 балла)__\n",
    "\n",
    "Модифицируйте реализацию так, чтобы можно было обучать логистическиую регрессию с $L_1$-регуляризацией (и даже одновременно с двумя видами). Проведите аналогичные эксперименты, считая $\\lambda_1 = 0.001, \\lambda_2 = 0$.\n",
    "\n",
    "Стоит помнить, что модуль — недифференцируемая в нуле функция, поэтому мы не можем применить обычный градиентный спуск. Вместо этого будем применить субградиентный спуск — аналогичный градиентному спуску метод, в котором используется субградиент функции. \n",
    "\n",
    "Вектор $g \\in \\mathbb{R}$ называется субградиентом выпуклой функции $f$ в точке $x$, если $\\forall z \\in \\mathbb{R}$ выполнено неравенство: $f(z) \\ge f(x) + g^T (z-x)$. Если функция $f$ дифференцируема в точке $x$, её субградиент в этой точке совпадает с градиентом. Субдифференциалом функции $f$ называют множество субградиентов в этой точке.\n",
    "\n",
    "Для $f(x) = |x|$ при $x = 0$ субдифференциал определяется неравенством $|z| \\ge gz$, поэтому $g \\in [-1, 1]$. \n",
    "\n",
    "На практике для стабильности процесса обучения для близких к нулю значений можно уменьшать градиент, умножая на небольшое число (например, 0.1-0.5) или делая его нулевым (только околонулевые координаты!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Выводы:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Из иследованного примера можно сделать выводы, что:_\n",
    "- _стохастическая логистическая регрессия меньше проваливается в локальные оптимумы, чем полная_\n",
    "- _стохастическая быстрее, чем полная_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f0e8d296974aed883d16a56c2fffe7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "auc_scores = []\n",
    "alphas_list = np.logspace(-4, 0, 20)\n",
    "for alpha in tqdm_notebook(alphas_list):\n",
    "    lr_sto = LogReg(gd_type='stochastic', lambda_2=1, tolerance=1e-6, max_iter=1000, alpha=alpha)\n",
    "    lr_sto.fit(Xcc, ycc)\n",
    "    y_pred = lr_sto.predict_proba(Xcc)[:, 1]\n",
    "    auc = roc_auc_score(ycc, y_pred)\n",
    "    auc_scores.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "plt.semilogx(alphas_list, auc_scores)\n",
    "plt.title('Зависимость ROC AUC от alpha')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('roc auc')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ Обучение логистической регрессии на реальных данных и оценка качества классификации.\n",
    "\n",
    "**(1 балл)**\n",
    "\n",
    "Полезные функции и классы из scikit-learn для этого задания: confusion_matrix, precision_recall_curve, average_precision_score, train_test_split, StandardScaler, roc-curve, roc_auc_score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные с актуального сейчас конкурса [Kaggle Porto Seguro’s Safe Driver Prediction](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction) (вам нужна только обучающая выборка). Задача состоит в определении водителей, которые в ближайший год воспользуются своей автомобильной страховкой (бинарная классификация). Но для нас важна будет не сама задача, а только её данные. При этом под нужды задания мы немного модифицируем датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', index_col=0)\n",
    "target = data.target.values\n",
    "data = data.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пересемплируем выборку так, чтобы положительных и отрицательных объектов в выборке было одинаковое число. Разделим на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some resampling\n",
    "np.random.seed(910)\n",
    "mask_plus = np.random.choice(np.where(target == 1)[0], 100000, replace=True)\n",
    "mask_zero = np.random.choice(np.where(target == 0)[0], 100000, replace=True)\n",
    "\n",
    "data = pd.concat((data.iloc[mask_plus], data.iloc[mask_zero]))\n",
    "target = np.hstack((target[mask_plus], target[mask_zero]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забудьте отнормировать признаки (можно воспользоваться StandardScaler или сделать это вручную). Пока не будем обращать внимание на то, что некоторые признаки категориальные (этим мы займёмся позже)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = np.hstack([np.zeros((X_train.shape[0], 1)), scaler.transform(X_train)])\n",
    "X_test = np.hstack([np.zeros((X_test.shape[0], 1)), scaler.transform(X_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50081\n",
       "1    49919\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1079,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train[y_train == 0] = -1\n",
    "y_test[y_test == 0] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите логистическую регрессию с удобными для вас параметрами. Сделайте предсказание на тестовой части выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройку ROC-кривую и Precision-Recall-кривую, посчитайте ROC-AUC и PR-AUC. Какие наблюдения и выводы по ним можно сделать? (В свободной форме)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, confusion_matrix, precision_recall_curve, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My stochastic ROC AUC is 0.615026977677\n",
      "Average precision score (Precision-Recall AUC) is 0.601886705408\n"
     ]
    }
   ],
   "source": [
    "lr_sto = LogReg(gd_type='stochastic')\n",
    "lr_sto.fit(X_train, y_train)\n",
    "y_pred_lr = lr_sto.predict_proba(X_test)[:, 1]\n",
    "print('My stochastic ROC AUC is', roc_auc_score(y_test, y_pred_lr))\n",
    "print('Average precision score (Precision-Recall AUC) is', average_precision_score(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[31749, 18170],\n",
       "       [23879, 26202]])"
      ]
     },
     "execution_count": 779,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Confusion matrix')\n",
    "y_pred_no_prob = [1 if x >= 0.5 else -1 for x in y_pred]\n",
    "confusion_matrix(y_test, y_pred_no_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_Из наблюдений можно сделать выводы, что в целом модель не очень хорошо позволяет разделить выборку, с чем связан низкий ROC AUC. Падение Precision с ростом Recall плавное, следовательно скорее всего в выборке нет подвыборки, сильно отличающейся по своим характеристикам от остальной части, иначе наблюдались бы резкие обрывы._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "plt.plot(fpr, tpr, color='red', lw=2, )\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_re_curve = precision_recall_curve(y_test, y_pred)\n",
    "precision, recall, _ = pr_re_curve\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.step(recall, precision, color='b')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предположим, что наш алгоритм должен обеспечивать полноту не менее 0.7. Какому порогу бинаризации вероятностей это будет соответствовать? Какую точность (precision) мы получим? Постройте матрицу ошибок для данного порога. Что вы можете сказать о таком алгоритме? (В свободной форме)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cm2df(cm, labels):\n",
    "    df = pd.DataFrame()\n",
    "    for i, row_label in enumerate(labels):\n",
    "        rowdata={}\n",
    "        for j, col_label in enumerate(labels): \n",
    "            rowdata[col_label]=cm[i,j]\n",
    "        df = df.append(pd.DataFrame.from_dict({row_label:rowdata}, orient='index'))\n",
    "    df = df[labels].copy()\n",
    "    df.index = ['Actual ' + x for x in df.index]\n",
    "    df.columns = ['Predicted ' + x for x in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Порог бинаризации для полноты не менее 0.7: 0.49011727728\n"
     ]
    }
   ],
   "source": [
    "y_score_for_recall, y_pred_for_recall = zip(*sorted(zip(y_pred, y_test), key=lambda x: x[0], reverse=True))\n",
    "y_score_for_recall = np.array(y_score_for_recall)\n",
    "y_pred_for_recall = np.array(y_pred_for_recall)\n",
    "y_pred_cumsum = np.cumsum(y_pred_for_recall == 1)\n",
    "y_recall = y_pred_cumsum / y_pred_cumsum.max()\n",
    "threshold = y_score_for_recall[np.where(y_recall >= 0.7)[0][0]]\n",
    "print('Порог бинаризации для полноты не менее 0.7:', threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision (TP / (TP + FP)) is 0.56415042724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "           Predicted -1  Predicted +1\n",
       "Actual -1         22834         27085\n",
       "Actual +1         15023         35058"
      ]
     },
     "execution_count": 854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, [1 if x >= threshold else -1 for x in y_pred])\n",
    "tp, fp = cm[1][1], cm[0][1]\n",
    "print('Precision (TP / (TP + FP)) is', tp / (tp + fp))\n",
    "cm2df(cm, ['-1', '+1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Данный алгоритм работает не очень - если хотим больший recall, то получаем точность близкую к рандому_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 3.__ Изучение влияния регуляризатора на процесс обучения\n",
    "\n",
    "__(0.5 балла)__\n",
    "\n",
    "Проверьте на практике, как влияет регуляризатор на процесс обучения (убывание функции потерь на обучающей и отложенной выборках). Чтобы считать функцию потерь на отложенной выборке после каждой итерации, запускайте процесс обучения логистической регрессии с параметром $max\\_iter=1$ и $w^{(0)}$, полученным на предыдущей итерации. Постройте два графика: на одном из них логистическая регрессия с коэффициентом регуляризации, равным 0, а на другом с некоторым разумным значением. На каждом графике одновременно должна быть и функция потерь для обучающей, и для тестовой выборки. Не забудьте сделать одинаковыми оси обоих графиков. Какие выводы вы можете сделать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xcc_train, Xcc_test, ycc_train, ycc_test = train_test_split(Xcc, ycc, train_size = 0.7, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iterations = list(range(3000))\n",
    "def get_losses(lambda_2):\n",
    "    train_losses, test_losses = [], []\n",
    "    w0 = None\n",
    "    for i in iterations:\n",
    "        lr = LogReg(gd_type='stochastic', lambda_2=lambda_2, max_iter = 1, w0 = w0)\n",
    "        lr.fit(Xcc_train, ycc_train)\n",
    "        train_losses.append(lr.calc_loss(Xcc_train, ycc_train))\n",
    "        test_losses.append(lr.calc_loss(Xcc_test, ycc_test))\n",
    "        w0 = lr.w\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lambda_2 in [0, 1.0]:\n",
    "    tr, te = get_losses(lambda_2)\n",
    "    plt.figure(figsize = (10, 5))\n",
    "    plt.plot(iterations, tr, 'b', iterations, te, 'r')\n",
    "    plt.title(f'Влияние регуляризатора на процесс обучения. Значение регуляризатора lambda_2: {lambda_2}')\n",
    "    plt.legend(['Train', 'Test'])\n",
    "    plt.ylim([0.66, 0.695])\n",
    "    plt.xlabel('lambda 2')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Выводы: С регуляризацией быстрее сходится, меньше переобучение (разница train - test loss). Однако, модель может не до конца обучиться._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Метод опорных векторов и калибровка вероятностней"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучение и применение метода опорных векторов.\n",
    "\n",
    "__(1 балл)__\n",
    "\n",
    "Обучите метод опорных векторов (в этот раз воспользуйтесь готовой реализацией LinearSVC из sklearn). Используйте уже загруженные и обработанные в предыдущей части данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.5)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = np.hstack([np.zeros((X_train.shape[0], 1)), scaler.transform(X_train)])\n",
    "X_test = np.hstack([np.zeros((X_test.shape[0], 1)), scaler.transform(X_test)])\n",
    "\n",
    "y_train[y_train == 0] = -1\n",
    "y_test[y_test == 0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 926,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90640313700098019"
      ]
     },
     "execution_count": 927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, dt.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svc = LinearSVC(random_state=1)\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На той же тестовой части посчитайте все те же метрики. Что вы можете сказать о полученных результатах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC: 0.623268020789\n",
      "Test ROC AUC: 0.620142035169\n",
      "Train average precision score (Precision-Recall AUC) is 0.612351376053\n",
      "Test average precision score (Precision-Recall AUC) is 0.609917146834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "           Predicted -1  Predicted +1\n",
       "Actual -1         31330         18674\n",
       "Actual +1         22878         27118"
      ]
     },
     "execution_count": 936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_svc_train = svc.decision_function(X_train)\n",
    "y_pred_svc = svc.decision_function(X_test)\n",
    "\n",
    "print('Train ROC AUC:', roc_auc_score(y_train, y_pred_svc_train))\n",
    "print('Test ROC AUC:', roc_auc_score(y_test, y_pred_svc))\n",
    "print('Train average precision score (Precision-Recall AUC) is', average_precision_score(y_train, y_pred_svc_train))\n",
    "print('Test average precision score (Precision-Recall AUC) is', average_precision_score(y_test, y_pred_svc))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_svc)\n",
    "plt.plot(fpr, tpr, color='red', lw=2, )\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()\n",
    "\n",
    "pr_re_curve = precision_recall_curve(y_test, y_pred_svc)\n",
    "precision, recall, _ = pr_re_curve\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.step(recall, precision, color='b')\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve')\n",
    "plt.show()\n",
    "\n",
    "cm2df(confusion_matrix(y_test, [1 if x > 0 else -1 for x in y_pred_svc]), ['-1', '+1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Модель линейная, по качеству не сильно отличается от логистической регрессии_\n",
    "_Переобучения не наблюдается_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В названии метода присутствуют некоторые \"опорные векторы\". Сгенерируйте синтетический датасет с помощью make_classification с 2 признаками, обучите на нём метод опорных векторов с линейным ядром. Визуализируйте разделяющую прямую, все объекты и выделите опорные вектора (атрибут support\\_vectors\\_). В этот раз вместо LinearSVC воспользуйтесь SVC с линейным ядром, так как только в нём есть информация об опорных векторах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_взято из_ http://scikit-learn.org/stable/auto_examples/svm/plot_svm_kernels.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "# Our dataset and targets\n",
    "X, Y = make_classification(n_samples=1000, n_classes=2, n_features=2, n_informative=2, \n",
    "                           n_repeated=0, n_redundant=0, n_clusters_per_class=2,\n",
    "                           class_sep = 2.0, random_state = 1)\n",
    "\n",
    "# figure number\n",
    "fignum = 1\n",
    "\n",
    "# fit the model\n",
    "for kernel in ('linear',):\n",
    "    clf = svm.SVC(kernel=kernel)\n",
    "    clf.fit(X, Y)\n",
    "\n",
    "    # plot the line, the points, and the nearest vectors to the plane\n",
    "    plt.figure(fignum, figsize=(10, 10))\n",
    "    plt.clf()\n",
    "\n",
    "    plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=80,\n",
    "                facecolors='none', zorder=10, edgecolors='k')\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, zorder=10, cmap=plt.cm.Paired,\n",
    "                edgecolors='k')\n",
    "\n",
    "    plt.axis('tight')\n",
    "    x_min = -3\n",
    "    x_max = 3\n",
    "    y_min = -3\n",
    "    y_max = 3\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    plt.figure(fignum, figsize=(4, 3))\n",
    "    plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.coolwarm)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'], linestyles=['--', '-', '--'],\n",
    "                levels=[-.5, 0, .5])\n",
    "\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "    fignum = fignum + 1\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ Калибровка вероятностей.\n",
    "\n",
    "__(1 балл)__\n",
    "\n",
    "Перейдём к оценке качества выдаваемых алгоритмами вероятностей. Начнём с калибровочных кривых. \n",
    "\n",
    "Допустим, алгоритм возвращает некоторые числа от нуля до единицы. Хорошо ли они оценивают вероятность? Для этого разобьем отрезок $[0, 1]$ на несколько маленьких отрезков одинаковой длины. Рассмотрим $i$-й отрезок с границами $[a_i, b_i]$ и предсказания $p_1, p_2, \\dots, p_k$, которые попали в него. Пусть им соответствуют истинные ответы $y_1, y_2, \\dots, y_k$. Если алгоритм выдает корректные вероятности, то среди этих истинных ответов должно быть примерно $(a_i + b_i) / 2$ единиц. Иными словами, если нарисовать кривую, у которой по оси X отложены центры отрезков, а по оси Y — доли единичных ответов этих в отрезках, то она должна оказаться диагональной. Ниже приведена функция, которая должна рисовать такие кривые. В ней допущено две ошибки — найдите и исправьте их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration_curve(y_test, preds, title):\n",
    "    bin_middle_points = []\n",
    "    bin_real_ratios = []\n",
    "    n_bins = 50\n",
    "    # чтобы l, r не шли от 0 и 1, а более плавно\n",
    "    space = np.linspace(np.min(preds), np.max(preds), n_bins)\n",
    "    for l, r in zip(space[:-1], space[1:]):\n",
    "#         l = 1.0 * i / n_bins\n",
    "#         r = 1.0 * (i + 1) / n_bins\n",
    "        # вместо разницы - берем среднее для середины отрезка\n",
    "        if len(y_test[(preds >= l) & (preds < r)] == 1) < 10:\n",
    "            continue\n",
    "        else:\n",
    "            mean = np.mean(y_test[(preds >= l) & (preds < r)] == 1)\n",
    "        bin_middle_points.append((l + r) / 2)\n",
    "        # берем не минимум, а среднее по реальным ответам в корзине\n",
    "        bin_real_ratios.append(mean)\n",
    "    plt.title(title)\n",
    "    plt.plot(bin_middle_points, bin_real_ratios)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотройте калибровочные кривые для логистической регрессии и метода опорных векторов (на той же самой выборке с тем же самым разбиением — можно использовать уже полученные ранее предсказания). Изучите распределение ответов классификаторов (постройте гистограммы с помощью plt.hist). Чем они различаются? Чем вы можете объяснить это?\n",
    "\n",
    "Заметим, что метод опорных векторов не умеет predict_proba, но имеет метод decision_function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_calibration_curve(y_test, y_pred_svc, 'Калибровочная кривая для LinearSVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(y_test, y_pred_lr, 'Калибровочная кривая для логистической регрессии')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуйтесь CalibratedClassifierCV из sklearn для калибровки вероятностей метода опорных векторов на обучении и постройте с его помощью предсказания для тестовой выборки. Нарисуйте для них калибровочную кривую. Улучшилась ли она?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "cccv = CalibratedClassifierCV(LinearSVC())\n",
    "\n",
    "cccv.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cccv = svc.decision_function(X_test)\n",
    "\n",
    "plot_calibration_curve(y_test, y_pred_cccv, 'Калибровочная кривая для CalibratedClassifierCV от LinearSVC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Чисто визуально выглядит получше_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Бонусное задание (1 балл).__ Реализуйте свою функцию для калибровки вероятностей. Опишите ваш подход и продемонстрируйте результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 4. Работа с категориальными переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части мы научимся обрабатывать категориальные переменные, так как закодировать их в виде чисел недостаточно (это задаёт некоторый порядок, которого на категориальных переменных может и не быть). Существует два основных способа обработки категориальных значений:\n",
    "- One-hot-кодирование\n",
    "- Счётчики (CTR, mean-target кодирование, ...) — каждый категориальный признак заменяется на среднее значение целевой переменной по всем объектам, имеющим одинаковое значение в этом признаке.\n",
    "\n",
    "Начнём с one-hot-кодирования. Допустим наш категориальный признак $f_j(x)$ принимает значения из множества $C=\\{c_1, \\dots, c_m\\}$. Заменим его на $m$ бинарных признаков $b_1(x), \\dots, b_m(x)$, каждый из которых является индикатором одного из возможных категориальных значений:\n",
    "$$\n",
    "b_i(x) = [f_j(x) = c_i]\n",
    "$$\n",
    "\n",
    "__Задание 1.__ Закодируйте все категориальные признаки с помощью one-hot-кодирования. Обучите логистическую регрессию и посмотрите, как изменилось качество модели (с тем, что было ранее). Измерьте время, потребовавшееся на обучение модели.\n",
    "\n",
    "__(0.5 балла)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', index_col=0)\n",
    "target = data.target.values\n",
    "data = data.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import gc\n",
    "ohe = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "885"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some resampling\n",
    "np.random.seed(910)\n",
    "mask_plus = np.random.choice(np.where(target == 1)[0], 100000, replace=True)\n",
    "mask_zero = np.random.choice(np.where(target == 0)[0], 100000, replace=True)\n",
    "\n",
    "data = pd.concat((data.iloc[mask_plus], data.iloc[mask_zero]))\n",
    "target = np.hstack((target[mask_plus], target[mask_zero]))\n",
    "\n",
    "def change_values(values):\n",
    "    change_dict = dict({v: n for n, v in enumerate(sorted(np.unique(values)))})\n",
    "    values = [change_dict[x] for x in values]\n",
    "    return values\n",
    "\n",
    "data_ohe = data[[x for x in data.columns if x.endswith('_cat')]]\n",
    "data_ohe = data_ohe.apply(lambda x: change_values(x.tolist()), axis = 0)\n",
    "ohe.fit(data_ohe)\n",
    "data_ohe = ohe.transform(data_ohe)\n",
    "data_ohe_dense = pd.DataFrame(data_ohe.todense(), \n",
    "                              columns = [f'ohe_cat_{x}' for x in range(data_ohe.shape[1])]).astype(int)\n",
    "data_not_ohe = data.loc[:, [x for x in data.columns if not x.endswith('_cat')]]\n",
    "data_ohe_dense.index = data_not_ohe.index\n",
    "data = pd.concat([data_not_ohe, data_ohe_dense], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.5)\n",
    "del data, data_ohe_dense, data_ohe, data_not_ohe\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC на выборке с One Hot encoding: 0.6329280419141639\n"
     ]
    }
   ],
   "source": [
    "lm = LogisticRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f'ROC AUC на выборке с One Hot encoding: {auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно было заменить, one-hot-кодирование может сильно увеличивать количество признаков в датасете, что сказывается на памяти, особенно, если некоторый признак имеет большое количество значений. Эту проблему решает другой способ кодирование категориальных признаков — счётчики. Основная идея в том, что нам важны не сами категории, а значения целевой переменной, которые имеют объекты этой категории. Каждый категориальный признак мы заменим средним значением целевой переменной по всем объектам этой же категории:\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)][y_i = +1]}{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)]}\n",
    "$$\n",
    "\n",
    "__Задание 2.__ Закодируйте категориальные переменные с помощью счётчиков (ровно так, как описано выше без каких-либо хитростей). Обучите логистическую регрессию и посмотрите на качество модели на тестовом множестве. Сравните время обучения с предыдущим экспериментов. Заметили ли вы что-то интересное?\n",
    "\n",
    "__(1 балл)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv', index_col=0)\n",
    "target = data.target.values\n",
    "data = data.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {
    "scrolled": true
   },
   "outputs": []
   "source": [
    "cat_cols = [x for x in data.columns if x.endswith('_cat')]\n",
    "data[cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some resampling\n",
    "np.random.seed(910)\n",
    "mask_plus = np.random.choice(np.where(target == 1)[0], 100000, replace=True)\n",
    "mask_zero = np.random.choice(np.where(target == 0)[0], 100000, replace=True)\n",
    "\n",
    "data = pd.concat((data.iloc[mask_plus], data.iloc[mask_zero]))\n",
    "target = np.hstack((target[mask_plus], target[mask_zero]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.5, random_state = 1)\n",
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cheat_values(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    cat_dict = {}\n",
    "    for uniq_value in np.unique(x):\n",
    "        cat_dict[uniq_value] = np.mean(y[x == uniq_value])\n",
    "    return cat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for column in cat_cols:\n",
    "    cheat_dict = get_cheat_values(X_train.loc[:, column], y_train)\n",
    "    X_train.loc[:, column] = [cheat_dict[v] for v in X_train.loc[:, column]]\n",
    "    X_test.loc[:, column] = [cheat_dict[v] for v in X_test.loc[:, column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC на обучающей выборке, с примитивными счетчиками: 0.6291076578301372\n",
      "ROC AUC на тестовой выборке, с примитивными счетчиками: 0.6258865913767704\n"
     ]
    }
   ],
   "source": [
    "lm = LogisticRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lm.predict_proba(X_train)[:, 1]\n",
    "auc = roc_auc_score(y_train, y_pred)\n",
    "print(f'ROC AUC на обучающей выборке, с примитивными счетчиками: {auc}')\n",
    "\n",
    "y_pred = lm.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "print(f'ROC AUC на тестовой выборке, с примитивными счетчиками: {auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Слегка переобучается_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отметим, что такие признаки сами по себе являются классификаторами и, обучаясь на них, мы допускаем \"утечку\" целевой переменной в признаки. Это ведёт к переобучению, поэтому считать такие признаки необходимо таким образом, чтобы при вычислении для конкретного объекта его целевая метка не использовалась. Это можно делать следующими способами:\n",
    "- вычислять значение счётчика по всем объектам расположенным выше в датасете (например, если у нас выборка отсортирована по времени)\n",
    "- вычислять по фолдам, то есть делить выборку на некоторое количество частей и подсчитывать значение признаков по всем фолдам кроме текущего (как делается в кросс-валидации)\n",
    "- внесение некоторого шума в посчитанные признаки. \n",
    "\n",
    "__Задание 3.__ Реализуйте корректное вычисление счётчиков самым простым способом — добавление шума к значениям (необходимо соблюсти баланс между избавление от переобучения и полезностью признаков). Снова обучите логистическую регрессию, оцените качество. Сделайте выводы.\n",
    "\n",
    "__(0.25 балла)__\n",
    "\n",
    "__(Бонусная часть)__ Посчитайте корректные счётчики одним из двух способов описанных выше (не забудьте добавить и шум). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь ответьте на следующий вопрос: что будет, если некоторая категория встречается в выборке всего несколько раз? По этой причине производится сглаживание счётчиков. Например, на практике хорошие результаты показывает использование сглаживания средним по всей выборке:\n",
    "$$\n",
    "g_j(x, X) = \\frac{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)][y_i = +1] + C * global\\_mean}{\\sum_{i=1}^{l} [f_j(x) = f_j(x_i)] + C}\n",
    "$$\n",
    "где $global\\_mean$ — среднее значение целевой переменной по всей выборке, $C$ — параметр, определяющий степень сглаживания (например, можно использовать 10 или подобрать для каждого признака свой). Основная идея в том, что мы \"разбавляем\" среднее значение по некоторой категории глобальным средним значении. И тем меньше, чем большее количество объектов этой категории встречается в выборке. \n",
    "\n",
    "Однако для сглаживания вместо среднего значения целевой переменной можно использовать любое другое значение от 0 до 1 (этот параметр иногда называют $prior$). Можно сделать несколько признаков с разными значениями параметра. На практике в задачах бинарной классификации полезными бывают даже отрицательные значения!\n",
    "\n",
    "__Задание 4.__ Добавьте сглаживание, описанное выше и повторите эксперименты.\n",
    "\n",
    "__(0.75 балла)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Замечание.__ Усложнение методов вычисления счётчиков не делают результаты модели гарантированно лучше. Особенно с учётом того, что логистическая регрессия не такая сложная модель, чтобы переобучаться. Поэтому вы необязательно должны были получать на каждом шаге всё лучшие и лучшие результаты (но необходимые результаты у вас должны были получиться).\n",
    "\n",
    "Как вы должны были заметить, счётчики являются хорошей альтернативой one-hot-кодированию. Напишите, какие плюсы и минусы использования счётчиков по сравнению с one-hot-кодированием, вы заметили.\n",
    "\n",
    "__Ответ:__ ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5.** Какой лучший мем в 2k17?\n",
    "\n",
    "__Ответ:__ ...\n",
    "\n",
    "\n",
    "**Задание 6.** Поделитесь лучшим стикерпаком. Только там не должно быть преподавателей и ассистентов этого курса.\n",
    "\n",
    "__Ответ:__ ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 5 (бонус). Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части мы научимся использовать библиотеку [vowpal wabbit](https://github.com/JohnLangford/vowpal_wabbit). У неё есть несколько особенностей:\n",
    "- можно обучать только линейные модели, но за счёт большого количества опций и возможностей по усложнению, можно построить и довольно сложные вещи\n",
    "- можно обучаться на выборках, которые не помещаются в оперативную память\n",
    "- можно обрабатывать большое количество признаков (например, мешки слов текстов) и \"на ходу\" строить на них комбинации (не переделывать датасет)\n",
    "- другие особенности, как например, активное обучение и возможность распараллеленного обучения.\n",
    "\n",
    "Основные особенности при использовании следующие:\n",
    "- Свой формат данных: \"label |A feature1:value1 |B feature2:value2\", позволяющий, во-первых, указывать не все признаки (не нужно хранить много нулей в разреженных данных), а во-вторых, группировать и иметь возможность отключать или взаимодействовать (\"отключать\", добавлять квадратичные признаки и т.д.) сразу со всей группой признаков. По этой причине вам понадобится реализовать конвертер датасета и загрузку своих предсказаний, чтобы посчитать качество предсказаний.\n",
    "- Запуск обучения из командной строки (однако можно запускать эти же команды из ноутбука).\n",
    "\n",
    "В этот раз мы будем использовать данные с конкурса [Kaggle Avazu Click-Through Rate Prediction](https://www.kaggle.com/c/avazu-ctr-prediction) по предсказанию кликов (бинарная классификация). В обучающей выборке 40kk строк, так что у вас не должно быть желания загружать их в оперативную память. Предлагается взять первые 30kk строк в качестве обучающей выборке и оставшуюся часть для тестирования.\n",
    "\n",
    "__Задание 1.__ Работа с vowpal wabbit. \n",
    "\n",
    "- Скачайте данные, разделите их на обучающую и тестовую выборки.\n",
    "- Подготовьте функции для конвертирования датасета в формат vowpal wabbit и для загрузки предсказаний в ноутбук для подсчёта функционала.\n",
    "- Сделайте простейшее решение на vowpal wabbit. Оцените качество.\n",
    "- Изучите возможности и параметры vowpal wabbit. Поэксперементируйте. \n",
    "- Расскажите, что интересного вы узнали (какие-нибудь особенности, режимы работы, фишки, параметры).\n",
    "- Удалось ли вам улучшить качество базовой модели? Насколько? Что ещё можно было бы попробовать?\n",
    "\n",
    "В этом задании предусмотрены баллы по двум критериям:\n",
    "- достижение ROC-AUC на отложенной выборки более 0.738 __(1 балл)__\n",
    "- несколько занимательных фактов и возможностей vowpal-wabbit __(0.5 балла)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}